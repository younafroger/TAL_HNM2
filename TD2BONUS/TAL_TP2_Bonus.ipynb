{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#On réutilise nos fonctions créées du TP2\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re\n",
        "import glob\n",
        "import os\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "def read_corpus(file_path):\n",
        "    with open(file_path, \"r\") as infile:\n",
        "        content = infile.read()\n",
        "        content = content.lower()\n",
        "        content = re.sub(r\"[^\\w\\s']\", ' ', content)\n",
        "        content = re.sub(r'\\s+', ' ', content)\n",
        "    return content\n",
        "\n",
        "def split_corpus(content, lang):\n",
        "  splitted_content = []\n",
        "  splitted_content = nltk.tokenize.word_tokenize(content, lang)\n",
        "  return splitted_content\n",
        "\n",
        "def content_to_dict(splitted_content):\n",
        "    content_dict = {}\n",
        "    for word in splitted_content:\n",
        "        content_dict[word] = content_dict.get(word, 0) + 1\n",
        "    return content_dict\n",
        "\n",
        "def content_to_list(content_dict):\n",
        "    return sorted(content_dict.items(), key=lambda x: x[1], reverse=True)\n"
      ],
      "metadata": {
        "id": "SZK-5rwGUaMY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb069d93-60fa-4ac0-b21b-12023b29bbf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_p_at_20(most_frequent_words, stopwords_list):\n",
        "    top_20_frequent = set(most_frequent_words[:20])\n",
        "    top_20_stopwords = set(stopwords_list[:20])\n",
        "    common_words = top_20_frequent.intersection(top_20_stopwords)\n",
        "    return len(common_words) / 20\n",
        "\n",
        "def identify_language_for_folder(folder_path):\n",
        "    expected_language = os.path.basename(folder_path)\n",
        "    print(f\"Processing folder: {folder_path} (expected language: {expected_language})\")\n",
        "\n",
        "    files = glob.glob(f\"{folder_path}/*.txt\")\n",
        "    languages = ['english', 'french', 'spanish', 'greek', 'finnish', 'dutch']\n",
        "\n",
        "    stopwords_count = {lang: 0 for lang in languages}\n",
        "\n",
        "    for file_path in files:\n",
        "        print(f\"\\nFile: {file_path}\")\n",
        "\n",
        "        content = read_corpus(file_path)\n",
        "        splitted_content = split_corpus(content, expected_language)\n",
        "        content_dict = content_to_dict(splitted_content)\n",
        "        most_frequent_words = [word for word, _ in content_to_list(content_dict)]\n",
        "\n",
        "        best_p_at_20 = 0\n",
        "        best_stopwords_language = None\n",
        "\n",
        "        for stopwords_lang in languages:\n",
        "            stopwords_list = stopwords.words(stopwords_lang)\n",
        "            p_at_20 = compute_p_at_20(most_frequent_words, stopwords_list)\n",
        "            print(f\"P@20 for stopwords in {stopwords_lang}: {p_at_20}\")\n",
        "\n",
        "            if p_at_20 > best_p_at_20:\n",
        "                best_p_at_20 = p_at_20\n",
        "                best_stopwords_language = stopwords_lang\n",
        "\n",
        "        if best_stopwords_language:\n",
        "            print(f\"Best P@20 score for file {file_path} is with stopwords '{best_stopwords_language}': P@20 = {best_p_at_20}\")\n",
        "            stopwords_count[best_stopwords_language] += 1\n",
        "        else:\n",
        "            print(f\"No stopword list had a significant P@20 score for file {file_path}\")\n",
        "\n",
        "    print(\"\\nStopwords language count across all files in the folder:\")\n",
        "    for stopwords_lang, count in stopwords_count.items():\n",
        "        print(f\"{stopwords_lang}: {count}\")\n",
        "\n",
        "identify_language_for_folder('data/dutch')\n",
        "identify_language_for_folder('data/english')\n",
        "identify_language_for_folder('data/finnish')\n",
        "identify_language_for_folder('data/french')\n",
        "identify_language_for_folder('data/greek')\n",
        "identify_language_for_folder('data/spanish')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1nUsmAo5gtG",
        "outputId": "7727928a-1d2f-4078-e9dd-6fee22599f2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing folder: data/dutch (expected language: dutch)\n",
            "\n",
            "Stopwords language count across all files in the folder:\n",
            "english: 0\n",
            "french: 0\n",
            "spanish: 0\n",
            "greek: 0\n",
            "finnish: 0\n",
            "dutch: 0\n",
            "Processing folder: data/english (expected language: english)\n",
            "\n",
            "Stopwords language count across all files in the folder:\n",
            "english: 0\n",
            "french: 0\n",
            "spanish: 0\n",
            "greek: 0\n",
            "finnish: 0\n",
            "dutch: 0\n",
            "Processing folder: data/finnish (expected language: finnish)\n",
            "\n",
            "Stopwords language count across all files in the folder:\n",
            "english: 0\n",
            "french: 0\n",
            "spanish: 0\n",
            "greek: 0\n",
            "finnish: 0\n",
            "dutch: 0\n",
            "Processing folder: data/french (expected language: french)\n",
            "\n",
            "Stopwords language count across all files in the folder:\n",
            "english: 0\n",
            "french: 0\n",
            "spanish: 0\n",
            "greek: 0\n",
            "finnish: 0\n",
            "dutch: 0\n",
            "Processing folder: data/greek (expected language: greek)\n",
            "\n",
            "Stopwords language count across all files in the folder:\n",
            "english: 0\n",
            "french: 0\n",
            "spanish: 0\n",
            "greek: 0\n",
            "finnish: 0\n",
            "dutch: 0\n",
            "Processing folder: data/spanish (expected language: spanish)\n",
            "\n",
            "Stopwords language count across all files in the folder:\n",
            "english: 0\n",
            "french: 0\n",
            "spanish: 0\n",
            "greek: 0\n",
            "finnish: 0\n",
            "dutch: 0\n"
          ]
        }
      ]
    }
  ]
}